import numpy as np
import torch
import pickle
from pathlib import Path
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from torch.utils.data import DataLoader
import sys
import os

# ãƒ‘ã‚¹è¨­å®š
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from utils.btc_data import get_btc_data, create_features, prepare_data, BtcSequenceDataset
from predictor import predict_class, load_checkpoint

def evaluate_on_test_data():
    """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§è©³ç´°ãªè©•ä¾¡"""

    # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
    model, scaler, config = load_checkpoint()

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æº–å‚™
    df = get_btc_data(period="2y", interval="1h")
    df_with_features = create_features(df)

    H = config['horizon']
    thr = config['threshold']
    L = config['sequence_length']

    X_train, X_val, X_test, y_train, y_val, y_test, _ = prepare_data(
        df_with_features, horizon=H, threshold=thr
    )

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
    test_dataset = BtcSequenceDataset(X_test, y_test, L)
    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)

    # è©•ä¾¡å®Ÿè¡Œ
    model.eval()
    all_predictions = []
    all_targets = []
    all_probabilities = []

    device = next(model.parameters()).device

    with torch.no_grad():
        for batch_X, batch_y in test_loader:
            batch_X, batch_y = batch_X.to(device), batch_y.to(device)
            batch_y = batch_y.squeeze()

            outputs = model(batch_X)
            probs = torch.softmax(outputs, dim=1)
            _, predicted = outputs.max(1)

            all_predictions.extend(predicted.cpu().numpy())
            all_targets.extend(batch_y.cpu().numpy())
            all_probabilities.extend(probs.cpu().numpy())

    # çµæœè¡¨ç¤º
    class_names = ['Up', 'Down', 'Flat']

    print("\nğŸ“Š ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆè©•ä¾¡çµæœ:")
    print("=" * 50)
    print(classification_report(all_targets, all_predictions, target_names=class_names))

    print("\nğŸ”„ æ··åŒè¡Œåˆ—:")
    cm = confusion_matrix(all_targets, all_predictions)
    print("      ", "  ".join([f"{name:>6}" for name in class_names]))
    for true_name, row in zip(class_names, cm):
        print(f"{true_name:>4}: {' '.join([f'{val:6d}' for val in row])}")

    # ã‚¯ãƒ©ã‚¹åˆ¥ç²¾åº¦
    accuracy = accuracy_score(all_targets, all_predictions)
    print(f"\nğŸ¯ å…¨ä½“ç²¾åº¦: {accuracy:.3f} ({accuracy:.1%})")

    # ä¿¡é ¼åº¦åˆ¥ç²¾åº¦åˆ†æ
    probabilities = np.array(all_probabilities)
    max_probs = np.max(probabilities, axis=1)

    confidence_thresholds = [0.5, 0.6, 0.7, 0.8, 0.9]
    print(f"\nğŸ“ˆ ä¿¡é ¼åº¦åˆ¥ç²¾åº¦:")
    for threshold in confidence_thresholds:
        mask = max_probs >= threshold
        if np.sum(mask) > 0:
            conf_accuracy = accuracy_score(
                np.array(all_targets)[mask],
                np.array(all_predictions)[mask]
            )
            count = np.sum(mask)
            coverage = count / len(all_targets)
            print(f"   ä¿¡é ¼åº¦>={threshold:.1f}: {conf_accuracy:.3f} ({conf_accuracy:.1%}) "
                  f"[{count}ä»¶, ã‚«ãƒãƒ¬ãƒƒã‚¸{coverage:.1%}]")

    return all_predictions, all_targets, all_probabilities

def quick_prediction():
    """æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬ä¾‹"""
    print("\nğŸ”® æœ€æ–°ãƒ‡ãƒ¼ã‚¿äºˆæ¸¬...")

    model, scaler, config = load_checkpoint()

    # æœ€æ–°ãƒ‡ãƒ¼ã‚¿å–å¾—
    df = get_btc_data(period="7d", interval="1h")
    df_with_features = create_features(df)

    feature_cols = config['feature_columns']
    features = df_with_features[feature_cols].values
    L = config['sequence_length']

    # æœ€æ–°ã®ç³»åˆ—ã§äºˆæ¸¬
    latest_features = features[-L:]
    features_scaled = scaler.transform(latest_features.reshape(-1, latest_features.shape[-1]))
    features_scaled = features_scaled.reshape(latest_features.shape)

    device = next(model.parameters()).device
    X = torch.FloatTensor(features_scaled).unsqueeze(0).to(device)

    with torch.no_grad():
        logits = model(X)
        probs = torch.softmax(logits, dim=1).cpu().numpy()[0]

    class_names = ['Up', 'Down', 'Flat']
    predicted_class = np.argmax(probs)

    print(f"ğŸ¯ 4æ™‚é–“å¾Œã®ä¾¡æ ¼äºˆæ¸¬:")
    print(f"   äºˆæ¸¬: {class_names[predicted_class]}")
    print(f"   ä¿¡é ¼åº¦: {probs[predicted_class]:.3f}")
    print(f"   è©³ç´°ç¢ºç‡:")
    print(f"     Up:   {probs[0]:.3f}")
    print(f"     Down: {probs[1]:.3f}")
    print(f"     Flat: {probs[2]:.3f}")

# ===== ç°¡æ˜“ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ =====
def simple_backtest(model, scaler, config):
    # ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    df = get_btc_data(period="2y", interval="1h")
    df_with_features = create_features(df)

    # ç‰¹å¾´é‡ã‚’å–å¾—
    feature_cols = config['feature_columns']
    features = df_with_features[feature_cols].values

    # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆå¾ŒåŠ500ã‚µãƒ³ãƒ—ãƒ«ï¼‰
    test_start = len(features) - 500
    L = config['sequence_length']
    H = config['horizon']

    trades = []
    prices = df_with_features['Close'].values

    for i in range(test_start + L, len(features) - H):
        # éå»Læœ¬åˆ†ã®ç‰¹å¾´é‡ã‚’å–å¾—
        features_seq = features[i-L:i]

        # äºˆæ¸¬
        result = predict_class(model, scaler, features_seq)

        # å®Ÿéš›ã®å°†æ¥ãƒªã‚¿ãƒ¼ãƒ³
        current_price = prices[i]
        future_price = prices[i + H]
        actual_return = (future_price - current_price) / current_price

        # å®Ÿéš›ã®ã‚¯ãƒ©ã‚¹
        if actual_return > 0:
            actual_class = "up"
        else:
            actual_class = "down"

        # ãƒˆãƒ¬ãƒ¼ãƒ‰åˆ¤å®š
        conf = result["confidence"]
        p_up = result["probabilities"]["p_up"]
        p_down = result["probabilities"]["p_down"]
        edge = p_up - p_down

        predicted_class = "flat"
        if conf >= 0.55 and edge >= 0.10:
            predicted_class = "up"
        elif conf >= 0.55 and edge <= -0.10:
            predicted_class = "down"

        # äºˆæ¸¬ãŒflatãªã‚‰å–å¼•ãªã—ãªã®ã§ã€ç„¡è¦–
        if predicted_class == "flat":
            continue

        trades.append({
            'predicted_class': result["class"],
            'actual_class': actual_class,
            'confidence': conf,
            'actual_return': actual_return,
            'correct': predicted_class == actual_class
        })

    # æˆç¸¾é›†è¨ˆ
    total_predictions = len(trades)
    correct_predictions = sum(t['correct'] for t in trades)
    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0

    print(f"\nğŸ“Š äºˆæ¸¬ç²¾åº¦:")
    print(f"   ç·äºˆæ¸¬æ•°: {total_predictions}")
    print(f"   æ­£è§£æ•°: {correct_predictions}")
    print(f"   ç²¾åº¦: {accuracy:.1%}")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("ğŸ§ª ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³åˆ†é¡ãƒ¢ãƒ‡ãƒ« ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
    print("=" * 60)

    try:
        # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        model, scaler, config = load_checkpoint()

        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿è©•ä¾¡
        evaluate_on_test_data()
        # ç°¡æ˜“ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
        simple_backtest(model, scaler, config)

        # æœ€æ–°äºˆæ¸¬
        quick_prediction()

        print("\n" + "=" * 60)
        print("âœ… å…¨ãƒ†ã‚¹ãƒˆå®Œäº†!")

    except FileNotFoundError as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        print("\nğŸ’¡ è§£æ±ºæ–¹æ³•: modeling/btc_train.py ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„")
    except Exception as e:
        print(e)

if __name__ == "__main__":
    main()