import numpy as np
import torch
import pickle
from pathlib import Path
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from torch.utils.data import DataLoader
import sys
import os

# ãƒ‘ã‚¹è¨­å®š
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from utils.btc_data import get_btc_data, create_features, prepare_data, BtcSequenceDataset
from modeling.btc_model import BtcClassifier

def get_device():
    """ãƒ‡ãƒã‚¤ã‚¹ã‚’å–å¾—"""
    if torch.cuda.is_available():
        return torch.device('cuda')
    elif torch.backends.mps.is_available():
        return torch.device('mps')
    else:
        return torch.device('cpu')

# ===== è¨­å®š =====
CHECKPOINT_DIR = Path("checkpoints/btc_classifier")
MODEL_PATH = CHECKPOINT_DIR / "model.pt"
SCALER_PATH = CHECKPOINT_DIR / "scaler.pkl"
CONFIG_PATH = CHECKPOINT_DIR / "config.pkl"

def load_model():
    """å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
    print("ğŸ“‚ å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...")

    # ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
    if not all([MODEL_PATH.exists(), SCALER_PATH.exists(), CONFIG_PATH.exists()]):
        raise FileNotFoundError(
            f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\n"
            f"å…ˆã« modeling/btc_train.py ã‚’å®Ÿè¡Œã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã¦ãã ã•ã„ã€‚"
        )

    # è¨­å®šã‚’èª­ã¿è¾¼ã¿
    with open(CONFIG_PATH, 'rb') as f:
        config = pickle.load(f)

    # ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã‚’èª­ã¿è¾¼ã¿
    with open(SCALER_PATH, 'rb') as f:
        scaler = pickle.load(f)

    # ãƒ¢ãƒ‡ãƒ«ã‚’å†æ§‹ç¯‰
    model = BtcClassifier(
        input_dim=config['input_dim'],
        d_model=config['d_model'],
        nhead=config['nhead'],
        num_layers=config['num_layers'],
        dropout=config['dropout']
    )

    # å­¦ç¿’æ¸ˆã¿ã®é‡ã¿ã‚’èª­ã¿è¾¼ã¿
    device = get_device()
    model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
    model.to(device)
    model.eval()

    print(f"âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº† (ãƒ‡ãƒã‚¤ã‚¹: {device})")
    return model, scaler, config

def evaluate_on_test_data():
    """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§è©³ç´°ãªè©•ä¾¡"""
    print("ğŸ” ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®è©•ä¾¡é–‹å§‹...")

    # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
    model, scaler, config = load_model()

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æº–å‚™
    df = get_btc_data(period="2y", interval="1h")
    df_with_features = create_features(df)

    H = config['horizon']
    thr = config['threshold']
    L = config['sequence_length']

    X_train, X_val, X_test, y_train, y_val, y_test, _ = prepare_data(
        df_with_features, horizon=H, threshold=thr
    )

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
    test_dataset = BtcSequenceDataset(X_test, y_test, L)
    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)

    # è©•ä¾¡å®Ÿè¡Œ
    model.eval()
    all_predictions = []
    all_targets = []
    all_probabilities = []

    device = next(model.parameters()).device

    with torch.no_grad():
        for batch_X, batch_y in test_loader:
            batch_X, batch_y = batch_X.to(device), batch_y.to(device)
            batch_y = batch_y.squeeze()

            outputs = model(batch_X)
            probs = torch.softmax(outputs, dim=1)
            _, predicted = outputs.max(1)

            all_predictions.extend(predicted.cpu().numpy())
            all_targets.extend(batch_y.cpu().numpy())
            all_probabilities.extend(probs.cpu().numpy())

    # çµæœè¡¨ç¤º
    class_names = ['Up', 'Down', 'Flat']

    print("\nğŸ“Š ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆè©•ä¾¡çµæœ:")
    print("=" * 50)
    print(classification_report(all_targets, all_predictions, target_names=class_names))

    print("\nğŸ”„ æ··åŒè¡Œåˆ—:")
    cm = confusion_matrix(all_targets, all_predictions)
    print("      ", "  ".join([f"{name:>6}" for name in class_names]))
    for true_name, row in zip(class_names, cm):
        print(f"{true_name:>4}: {' '.join([f'{val:6d}' for val in row])}")

    # ã‚¯ãƒ©ã‚¹åˆ¥ç²¾åº¦
    accuracy = accuracy_score(all_targets, all_predictions)
    print(f"\nğŸ¯ å…¨ä½“ç²¾åº¦: {accuracy:.3f} ({accuracy:.1%})")

    # ä¿¡é ¼åº¦åˆ¥ç²¾åº¦åˆ†æ
    probabilities = np.array(all_probabilities)
    max_probs = np.max(probabilities, axis=1)

    confidence_thresholds = [0.5, 0.6, 0.7, 0.8, 0.9]
    print(f"\nğŸ“ˆ ä¿¡é ¼åº¦åˆ¥ç²¾åº¦:")
    for threshold in confidence_thresholds:
        mask = max_probs >= threshold
        if np.sum(mask) > 0:
            conf_accuracy = accuracy_score(
                np.array(all_targets)[mask],
                np.array(all_predictions)[mask]
            )
            count = np.sum(mask)
            coverage = count / len(all_targets)
            print(f"   ä¿¡é ¼åº¦>={threshold:.1f}: {conf_accuracy:.3f} ({conf_accuracy:.1%}) "
                  f"[{count}ä»¶, ã‚«ãƒãƒ¬ãƒƒã‚¸{coverage:.1%}]")

    return all_predictions, all_targets, all_probabilities

def backtest_simulation():
    """å–å¼•ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆï¼‰"""
    print("\nğŸ’° å–å¼•ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹...")

    model, scaler, config = load_model()

    # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ï¼ˆæœ€æ–°1ãƒ¶æœˆï¼‰
    df = get_btc_data(period="1mo", interval="1h")
    df_with_features = create_features(df)

    feature_cols = config['feature_columns']
    features = df_with_features[feature_cols].values
    prices = df_with_features['Close'].values

    L = config['sequence_length']
    H = config['horizon']
    thr = config['threshold']

    # å–å¼•ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    trades = []
    portfolio_value = 100000  # åˆæœŸè³‡æœ¬10ä¸‡å††
    fee_rate = 0.0004  # å–å¼•æ‰‹æ•°æ–™0.04%

    for i in range(L, len(features) - H):
        # ç‰¹å¾´é‡ç³»åˆ—
        features_seq = features[i-L:i]

        # æ­£è¦åŒ–
        features_scaled = scaler.transform(features_seq.reshape(-1, features_seq.shape[-1]))
        features_scaled = features_scaled.reshape(features_seq.shape)

        # äºˆæ¸¬
        device = next(model.parameters()).device
        X = torch.FloatTensor(features_scaled).unsqueeze(0).to(device)

        with torch.no_grad():
            logits = model(X)
            probs = torch.softmax(logits, dim=1).cpu().numpy()[0]

        # å®Ÿéš›ã®å°†æ¥ãƒªã‚¿ãƒ¼ãƒ³
        current_price = prices[i]
        future_price = prices[i + H]
        actual_return = (future_price - current_price) / current_price

        # å–å¼•åˆ¤å®š
        p_up, p_down, p_flat = probs[0], probs[1], probs[2]
        max_prob = max(probs)
        predicted_class = np.argmax(probs)

        action = 'hold'
        position_size = 0

        # å–å¼•ãƒ«ãƒ¼ãƒ«
        if max_prob >= 0.6:  # é«˜ä¿¡é ¼åº¦ã®å ´åˆã®ã¿å–å¼•
            edge = p_up - p_down
            if edge >= 0.2:  # å¼·ã„ä¸Šæ˜‡äºˆæ¸¬
                action = 'long'
                position_size = 0.1  # è³‡é‡‘ã®10%
            elif edge <= -0.2:  # å¼·ã„ä¸‹é™äºˆæ¸¬
                action = 'short'
                position_size = 0.1

        # æç›Šè¨ˆç®—
        pnl = 0
        if action == 'long':
            pnl = position_size * actual_return * portfolio_value - fee_rate * position_size * portfolio_value
        elif action == 'short':
            pnl = position_size * (-actual_return) * portfolio_value - fee_rate * position_size * portfolio_value

        portfolio_value += pnl

        trades.append({
            'action': action,
            'position_size': position_size,
            'predicted_class': ['up', 'down', 'flat'][predicted_class],
            'confidence': max_prob,
            'actual_return': actual_return,
            'pnl': pnl,
            'portfolio_value': portfolio_value
        })

    # çµæœé›†è¨ˆ
    total_trades = len([t for t in trades if t['action'] != 'hold'])
    total_pnl = sum(t['pnl'] for t in trades)
    final_return = (portfolio_value - 100000) / 100000

    winning_trades = len([t for t in trades if t['pnl'] > 0])
    win_rate = winning_trades / total_trades if total_trades > 0 else 0

    print(f"\nğŸ“Š ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœ:")
    print(f"   æœŸé–“: {len(trades)}æ™‚é–“")
    print(f"   ç·å–å¼•æ•°: {total_trades}")
    print(f"   å‹ç‡: {win_rate:.1%}")
    print(f"   ç·æç›Š: {total_pnl:,.0f}å††")
    print(f"   æœ€çµ‚åç›Šç‡: {final_return:.2%}")
    print(f"   æœ€çµ‚è³‡ç”£: {portfolio_value:,.0f}å††")

def quick_prediction():
    """æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬ä¾‹"""
    print("\nğŸ”® æœ€æ–°ãƒ‡ãƒ¼ã‚¿äºˆæ¸¬...")

    model, scaler, config = load_model()

    # æœ€æ–°ãƒ‡ãƒ¼ã‚¿å–å¾—
    df = get_btc_data(period="7d", interval="1h")
    df_with_features = create_features(df)

    feature_cols = config['feature_columns']
    features = df_with_features[feature_cols].values
    L = config['sequence_length']

    # æœ€æ–°ã®ç³»åˆ—ã§äºˆæ¸¬
    latest_features = features[-L:]
    features_scaled = scaler.transform(latest_features.reshape(-1, latest_features.shape[-1]))
    features_scaled = features_scaled.reshape(latest_features.shape)

    device = next(model.parameters()).device
    X = torch.FloatTensor(features_scaled).unsqueeze(0).to(device)

    with torch.no_grad():
        logits = model(X)
        probs = torch.softmax(logits, dim=1).cpu().numpy()[0]

    class_names = ['Up', 'Down', 'Flat']
    predicted_class = np.argmax(probs)

    print(f"ğŸ¯ 4æ™‚é–“å¾Œã®ä¾¡æ ¼äºˆæ¸¬:")
    print(f"   äºˆæ¸¬: {class_names[predicted_class]}")
    print(f"   ä¿¡é ¼åº¦: {probs[predicted_class]:.3f}")
    print(f"   è©³ç´°ç¢ºç‡:")
    print(f"     Up:   {probs[0]:.3f}")
    print(f"     Down: {probs[1]:.3f}")
    print(f"     Flat: {probs[2]:.3f}")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("ğŸ§ª ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³åˆ†é¡ãƒ¢ãƒ‡ãƒ« ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
    print("=" * 60)

    try:
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿è©•ä¾¡
        evaluate_on_test_data()

        # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
        backtest_simulation()

        # æœ€æ–°äºˆæ¸¬
        quick_prediction()

        print("\n" + "=" * 60)
        print("âœ… å…¨ãƒ†ã‚¹ãƒˆå®Œäº†!")

    except FileNotFoundError as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        print("\nğŸ’¡ è§£æ±ºæ–¹æ³•: modeling/btc_train.py ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„")
    except Exception as e:
        print(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    main()