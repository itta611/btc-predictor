import torch
import numpy as np
import pickle
from pathlib import Path
import argparse

from modeling.btc_model import BtcClassifier
from utils.get_device import get_device
from utils.btc_data import get_btc_data, create_features

CHECKPOINT_DIR = Path("checkpoints/btc_classifier")
MODEL_PATH = CHECKPOINT_DIR / "model.pt"
SCALER_PATH = CHECKPOINT_DIR / "scaler.pkl"
CONFIG_PATH = CHECKPOINT_DIR / "config.pkl"

# ===== ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­ã¿è¾¼ã¿ =====
def load_checkpoint():
    print("ğŸ“‚ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­ã¿è¾¼ã¿ä¸­...")

    # ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
    if not all([MODEL_PATH.exists(), SCALER_PATH.exists(), CONFIG_PATH.exists()]):
        raise FileNotFoundError(
            f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\n"
            f"å…ˆã« btc_train.py ã‚’å®Ÿè¡Œã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã¦ãã ã•ã„ã€‚\n"
            f"å¿…è¦ãƒ•ã‚¡ã‚¤ãƒ«: {MODEL_PATH}, {SCALER_PATH}, {CONFIG_PATH}"
        )

    # è¨­å®šã‚’èª­ã¿è¾¼ã¿
    with open(CONFIG_PATH, 'rb') as f:
        config = pickle.load(f)

    # ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã‚’èª­ã¿è¾¼ã¿
    with open(SCALER_PATH, 'rb') as f:
        scaler = pickle.load(f)

    # ãƒ¢ãƒ‡ãƒ«ã‚’å†æ§‹ç¯‰
    model = BtcClassifier(
        input_dim=config['input_dim'],
        d_model=config['d_model'],
        nhead=config['nhead'],
        num_layers=config['num_layers'],
        dropout=config['dropout']
    )

    # å­¦ç¿’æ¸ˆã¿ã®é‡ã¿ã‚’èª­ã¿è¾¼ã¿
    device = get_device()
    model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
    model.to(device)
    model.eval()  # æ¨è«–ãƒ¢ãƒ¼ãƒ‰ã«è¨­å®š

    print(f"âœ… ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­ã¿è¾¼ã¿å®Œäº†:")
    print(f"   ãƒ¢ãƒ‡ãƒ«: {config['input_dim']}ç‰¹å¾´é‡ â†’ 3ã‚¯ãƒ©ã‚¹")
    print(f"   ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}")

    return model, scaler, config

# ===== æ¨è«–é–¢æ•° =====
def predict_proba(model, scaler, features_sequence):
    """
    1ã¤ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«å¯¾ã—ã¦äºˆæ¸¬ç¢ºç‡ã‚’è¿”ã™

    Args:
        model: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
        scaler: å­¦ç¿’æ™‚ã«ä½¿ã£ãŸã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼
        features_sequence: [L, F] ã®ç‰¹å¾´é‡ç³»åˆ—

    Returns:
        dict: {"p_up": float, "p_down": float, "p_flat": float}
    """
    device = next(model.parameters()).device

    # æ­£è¦åŒ–
    features_scaled = scaler.transform(features_sequence.reshape(-1, features_sequence.shape[-1]))
    features_scaled = features_scaled.reshape(features_sequence.shape)

    # ãƒ†ãƒ³ã‚½ãƒ«åŒ–ã—ã¦ãƒãƒƒãƒæ¬¡å…ƒè¿½åŠ 
    X = torch.FloatTensor(features_scaled).unsqueeze(0).to(device)  # [1, L, F]

    with torch.no_grad():
        logits = model(X)  # [1, 3]
        probs = torch.softmax(logits, dim=1).cpu().numpy()[0]  # [3]

    return {
        "p_up": float(probs[0]),
        "p_down": float(probs[1]),
        "p_flat": float(probs[2])
    }

def predict_class(model, scaler, features_sequence):
    """
    1ã¤ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«å¯¾ã—ã¦äºˆæ¸¬ã‚¯ãƒ©ã‚¹ã‚’è¿”ã™

    Args:
        model: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
        scaler: å­¦ç¿’æ™‚ã«ä½¿ã£ãŸã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼
        features_sequence: [L, F] ã®ç‰¹å¾´é‡ç³»åˆ—

    Returns:
        dict: {"class": str, "confidence": float, "probabilities": dict}
    """
    probs = predict_proba(model, scaler, features_sequence)

    # æœ€ã‚‚ç¢ºç‡ã®é«˜ã„ã‚¯ãƒ©ã‚¹ã‚’é¸æŠ
    class_names = ["up", "down", "flat"]
    class_probs = [probs["p_up"], probs["p_down"], probs["p_flat"]]

    max_idx = np.argmax(class_probs)
    predicted_class = class_names[max_idx]
    confidence = class_probs[max_idx]

    return {
        "class": predicted_class,
        "confidence": confidence,
        "probabilities": probs
    }

# ===== ã‚µãƒ³ãƒ—ãƒ«æ¨è«– =====
def run_sample_prediction(model, scaler, config):
    """
    ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§ã®æ¨è«–ä¾‹ã‚’å®Ÿè¡Œ
    """
    print("ğŸ”® ã‚µãƒ³ãƒ—ãƒ«æ¨è«–å®Ÿè¡Œä¸­...")

    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    df = get_btc_data(period="7d", interval="1h")
    df_with_features = create_features(df)

    # ç‰¹å¾´é‡ã‚’å–å¾—
    feature_cols = config['feature_columns']
    features = df_with_features[feature_cols].values

    # æœ€æ–°ã®Læœ¬åˆ†ã‚’ä½¿ã£ã¦æ¨è«–
    L = config['sequence_length']
    latest_features = features[-L:]

    # æ¨è«–å®Ÿè¡Œ
    result = predict_class(model, scaler, latest_features)

    print(f"\nğŸ¯ æ¨è«–çµæœ:")
    print(f"   äºˆæ¸¬ã‚¯ãƒ©ã‚¹: {result['class']}")
    print(f"   ä¿¡é ¼åº¦: {result['confidence']:.3f}")
    print(f"   è©³ç´°ç¢ºç‡:")
    print(f"     Up:   {result['probabilities']['p_up']:.3f}")
    print(f"     Down: {result['probabilities']['p_down']:.3f}")
    print(f"     Flat: {result['probabilities']['p_flat']:.3f}")

    # å–å¼•æ¨å¥¨
    conf = result['confidence']
    edge = result['probabilities']['p_up'] - result['probabilities']['p_down']

    if conf >= 0.55 and edge >= 0.10:
        recommendation = "ğŸŸ¢ LONGæ¨å¥¨"
    elif conf >= 0.55 and edge <= -0.10:
        recommendation = "ğŸ”´ SHORTæ¨å¥¨"
    else:
        recommendation = "âšª HOLDæ¨å¥¨ï¼ˆç¢ºä¿¡åº¦ä¸è¶³ï¼‰"

    print(f"   å–å¼•æ¨å¥¨: {recommendation}")

# ===== ãƒ¡ã‚¤ãƒ³é–¢æ•° =====
def main():
    parser = argparse.ArgumentParser(description='ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³åˆ†é¡ãƒ¢ãƒ‡ãƒ«æ¨è«–')
    parser.add_argument('--mode', choices=['predict'],
                       default='predict', help='å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰')
    args = parser.parse_args()

    print("ğŸ”® ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³ä¾¡æ ¼åˆ†é¡ãƒ¢ãƒ‡ãƒ«æ¨è«–é–‹å§‹!")
    print("=" * 60)

    try:
        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­ã¿è¾¼ã¿
        model, scaler, config = load_checkpoint()

        if args.mode == 'predict':
            # ã‚µãƒ³ãƒ—ãƒ«æ¨è«–
            run_sample_prediction(model, scaler, config)

        print("\n" + "=" * 60)
        print("âœ… æ¨è«–å®Œäº†!")

    except FileNotFoundError as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        print("\nğŸ’¡ è§£æ±ºæ–¹æ³•:")
        print("   1. ã¾ãš btc_train.py ã‚’å®Ÿè¡Œã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã¦ãã ã•ã„")
        print("   2. å­¦ç¿’å®Œäº†å¾Œã€å†åº¦ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")

    except Exception as e:
        print(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    main()