#!/usr/bin/env python3
"""
ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³åˆ†é¡ãƒ¢ãƒ‡ãƒ«ã®æ¨è«–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import torch
import numpy as np
import pickle
from pathlib import Path
import argparse

from modeling.btc_model import BtcClassifier
from utils.get_device import get_device
from utils.btc_data import get_btc_data, create_features

# ===== è¨­å®š =====
CHECKPOINT_DIR = Path("checkpoints/btc_classifier")
MODEL_PATH = CHECKPOINT_DIR / "model.pt"
SCALER_PATH = CHECKPOINT_DIR / "scaler.pkl"
CONFIG_PATH = CHECKPOINT_DIR / "config.pkl"

# ===== ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­ã¿è¾¼ã¿ =====
def load_checkpoint():
    """
    ä¿å­˜ã•ã‚ŒãŸãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã€è¨­å®šã‚’èª­ã¿è¾¼ã¿
    """
    print("ğŸ“‚ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­ã¿è¾¼ã¿ä¸­...")

    # ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
    if not all([MODEL_PATH.exists(), SCALER_PATH.exists(), CONFIG_PATH.exists()]):
        raise FileNotFoundError(
            f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\n"
            f"å…ˆã« btc_train.py ã‚’å®Ÿè¡Œã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã¦ãã ã•ã„ã€‚\n"
            f"å¿…è¦ãƒ•ã‚¡ã‚¤ãƒ«: {MODEL_PATH}, {SCALER_PATH}, {CONFIG_PATH}"
        )

    # è¨­å®šã‚’èª­ã¿è¾¼ã¿
    with open(CONFIG_PATH, 'rb') as f:
        config = pickle.load(f)

    # ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã‚’èª­ã¿è¾¼ã¿
    with open(SCALER_PATH, 'rb') as f:
        scaler = pickle.load(f)

    # ãƒ¢ãƒ‡ãƒ«ã‚’å†æ§‹ç¯‰
    model = BtcClassifier(
        input_dim=config['input_dim'],
        d_model=config['d_model'],
        nhead=config['nhead'],
        num_layers=config['num_layers'],
        dropout=config['dropout']
    )

    # å­¦ç¿’æ¸ˆã¿ã®é‡ã¿ã‚’èª­ã¿è¾¼ã¿
    device = get_device()
    model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
    model.to(device)
    model.eval()  # æ¨è«–ãƒ¢ãƒ¼ãƒ‰ã«è¨­å®š

    print(f"âœ… ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­ã¿è¾¼ã¿å®Œäº†:")
    print(f"   ãƒ¢ãƒ‡ãƒ«: {config['input_dim']}ç‰¹å¾´é‡ â†’ 3ã‚¯ãƒ©ã‚¹")
    print(f"   ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}")

    return model, scaler, config

# ===== æ¨è«–é–¢æ•° =====
def predict_proba(model, scaler, features_sequence):
    """
    1ã¤ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«å¯¾ã—ã¦äºˆæ¸¬ç¢ºç‡ã‚’è¿”ã™

    Args:
        model: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
        scaler: å­¦ç¿’æ™‚ã«ä½¿ã£ãŸã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼
        features_sequence: [L, F] ã®ç‰¹å¾´é‡ç³»åˆ—

    Returns:
        dict: {"p_up": float, "p_down": float, "p_flat": float}
    """
    device = next(model.parameters()).device

    # æ­£è¦åŒ–
    features_scaled = scaler.transform(features_sequence.reshape(-1, features_sequence.shape[-1]))
    features_scaled = features_scaled.reshape(features_sequence.shape)

    # ãƒ†ãƒ³ã‚½ãƒ«åŒ–ã—ã¦ãƒãƒƒãƒæ¬¡å…ƒè¿½åŠ 
    X = torch.FloatTensor(features_scaled).unsqueeze(0).to(device)  # [1, L, F]

    with torch.no_grad():
        logits = model(X)  # [1, 3]
        probs = torch.softmax(logits, dim=1).cpu().numpy()[0]  # [3]

    return {
        "p_up": float(probs[0]),
        "p_down": float(probs[1]),
        "p_flat": float(probs[2])
    }

def predict_class(model, scaler, features_sequence):
    """
    1ã¤ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«å¯¾ã—ã¦äºˆæ¸¬ã‚¯ãƒ©ã‚¹ã‚’è¿”ã™

    Args:
        model: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
        scaler: å­¦ç¿’æ™‚ã«ä½¿ã£ãŸã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼
        features_sequence: [L, F] ã®ç‰¹å¾´é‡ç³»åˆ—

    Returns:
        dict: {"class": str, "confidence": float, "probabilities": dict}
    """
    probs = predict_proba(model, scaler, features_sequence)

    # æœ€ã‚‚ç¢ºç‡ã®é«˜ã„ã‚¯ãƒ©ã‚¹ã‚’é¸æŠ
    class_names = ["up", "down", "flat"]
    class_probs = [probs["p_up"], probs["p_down"], probs["p_flat"]]

    max_idx = np.argmax(class_probs)
    predicted_class = class_names[max_idx]
    confidence = class_probs[max_idx]

    return {
        "class": predicted_class,
        "confidence": confidence,
        "probabilities": probs
    }

# ===== ç°¡æ˜“ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ =====
def simple_backtest(model, scaler, config):
    """
    ç°¡å˜ãªå–å¼•ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
    """
    print("ğŸ’° ç°¡æ˜“ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")

    # ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    df = get_btc_data(period="1mo", interval="1h")
    df_with_features = create_features(df)

    # ç‰¹å¾´é‡ã‚’å–å¾—
    feature_cols = config['feature_columns']
    features = df_with_features[feature_cols].values

    # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆå¾ŒåŠ500ã‚µãƒ³ãƒ—ãƒ«ï¼‰
    test_start = len(features) - 500
    L = config['sequence_length']
    H = config['horizon']
    thr = config['threshold']

    trades = []
    prices = df_with_features['Close'].values

    for i in range(test_start + L, len(features) - H):
        # éå»Læœ¬åˆ†ã®ç‰¹å¾´é‡ã‚’å–å¾—
        features_seq = features[i-L:i]

        # äºˆæ¸¬
        result = predict_class(model, scaler, features_seq)

        # å®Ÿéš›ã®å°†æ¥ãƒªã‚¿ãƒ¼ãƒ³
        current_price = prices[i]
        future_price = prices[i + H]
        actual_return = (future_price - current_price) / current_price

        # å®Ÿéš›ã®ã‚¯ãƒ©ã‚¹
        if actual_return >= thr:
            actual_class = "up"
        elif actual_return <= -thr:
            actual_class = "down"
        else:
            actual_class = "flat"

        # ãƒˆãƒ¬ãƒ¼ãƒ‰åˆ¤å®š
        conf = result["confidence"]
        p_up = result["probabilities"]["p_up"]
        p_down = result["probabilities"]["p_down"]
        edge = p_up - p_down

        action = 'hold'
        if conf >= 0.55 and edge >= 0.10:
            action = 'long'
        elif conf >= 0.55 and edge <= -0.10:
            action = 'short'

        trades.append({
            'action': action,
            'predicted_class': result["class"],
            'actual_class': actual_class,
            'confidence': conf,
            'actual_return': actual_return,
            'correct': result["class"] == actual_class
        })

    # æˆç¸¾é›†è¨ˆ
    total_predictions = len(trades)
    correct_predictions = sum(t['correct'] for t in trades)
    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0

    total_trades = len([t for t in trades if t['action'] != 'hold'])
    long_trades = [t for t in trades if t['action'] == 'long']
    short_trades = [t for t in trades if t['action'] == 'short']

    # æ‰‹æ•°æ–™
    fee_rate = 0.000  # 0.04%

    total_pnl = 0
    successful_trades = 0

    for trade in trades:
        if trade['action'] == 'long':
            # ãƒ­ãƒ³ã‚°ãŒæˆåŠŸ = å®Ÿéš›ã«ä¸Šæ˜‡
            if trade['actual_class'] == 'up':
                pnl = thr - fee_rate  # åˆ©ç›Š - æ‰‹æ•°æ–™
                successful_trades += 1
            else:
                pnl = -thr - fee_rate  # æå¤± - æ‰‹æ•°æ–™
            total_pnl += pnl

        elif trade['action'] == 'short':
            # ã‚·ãƒ§ãƒ¼ãƒˆãŒæˆåŠŸ = å®Ÿéš›ã«ä¸‹é™
            if trade['actual_class'] == 'down':
                pnl = thr - fee_rate
                successful_trades += 1
            else:
                pnl = -thr - fee_rate
            total_pnl += pnl

    trade_win_rate = successful_trades / total_trades if total_trades > 0 else 0
    avg_pnl = total_pnl / total_trades if total_trades > 0 else 0

    print(f"\nğŸ“Š äºˆæ¸¬ç²¾åº¦:")
    print(f"   ç·äºˆæ¸¬æ•°: {total_predictions}")
    print(f"   æ­£è§£æ•°: {correct_predictions}")
    print(f"   ç²¾åº¦: {accuracy:.1%}")

    print(f"\nğŸ’¼ å–å¼•ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœ:")
    print(f"   ç·å–å¼•æ•°: {total_trades}")
    print(f"   ãƒ­ãƒ³ã‚°: {len(long_trades)}, ã‚·ãƒ§ãƒ¼ãƒˆ: {len(short_trades)}")
    print(f"   å–å¼•å‹ç‡: {trade_win_rate:.1%}")
    print(f"   ç·æç›Š: {total_pnl:.1%}")
    print(f"   å¹³å‡æç›Š: {avg_pnl:.3%}")
    print(f"   æ‰‹æ•°æ–™è€ƒæ…®æ¸ˆã¿ (ç‰‡é“{fee_rate:.2%})")

# ===== ã‚µãƒ³ãƒ—ãƒ«æ¨è«– =====
def run_sample_prediction(model, scaler, config):
    """
    ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§ã®æ¨è«–ä¾‹ã‚’å®Ÿè¡Œ
    """
    print("ğŸ”® ã‚µãƒ³ãƒ—ãƒ«æ¨è«–å®Ÿè¡Œä¸­...")

    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    df = get_btc_data(period="7d", interval="1h")
    df_with_features = create_features(df)

    # ç‰¹å¾´é‡ã‚’å–å¾—
    feature_cols = config['feature_columns']
    features = df_with_features[feature_cols].values

    # æœ€æ–°ã®Læœ¬åˆ†ã‚’ä½¿ã£ã¦æ¨è«–
    L = config['sequence_length']
    latest_features = features[-L:]

    # æ¨è«–å®Ÿè¡Œ
    result = predict_class(model, scaler, latest_features)

    print(f"\nğŸ¯ æ¨è«–çµæœ:")
    print(f"   äºˆæ¸¬ã‚¯ãƒ©ã‚¹: {result['class']}")
    print(f"   ä¿¡é ¼åº¦: {result['confidence']:.3f}")
    print(f"   è©³ç´°ç¢ºç‡:")
    print(f"     Up:   {result['probabilities']['p_up']:.3f}")
    print(f"     Down: {result['probabilities']['p_down']:.3f}")
    print(f"     Flat: {result['probabilities']['p_flat']:.3f}")

    # å–å¼•æ¨å¥¨
    conf = result['confidence']
    edge = result['probabilities']['p_up'] - result['probabilities']['p_down']

    if conf >= 0.55 and edge >= 0.10:
        recommendation = "ğŸŸ¢ LONGæ¨å¥¨"
    elif conf >= 0.55 and edge <= -0.10:
        recommendation = "ğŸ”´ SHORTæ¨å¥¨"
    else:
        recommendation = "âšª HOLDæ¨å¥¨ï¼ˆç¢ºä¿¡åº¦ä¸è¶³ï¼‰"

    print(f"   å–å¼•æ¨å¥¨: {recommendation}")

# ===== ãƒ¡ã‚¤ãƒ³é–¢æ•° =====
def main():
    parser = argparse.ArgumentParser(description='ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³åˆ†é¡ãƒ¢ãƒ‡ãƒ«æ¨è«–')
    parser.add_argument('--mode', choices=['predict', 'backtest', 'both'],
                       default='both', help='å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰')
    args = parser.parse_args()

    print("ğŸ”® ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³ä¾¡æ ¼åˆ†é¡ãƒ¢ãƒ‡ãƒ«æ¨è«–é–‹å§‹!")
    print("=" * 60)

    try:
        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­ã¿è¾¼ã¿
        model, scaler, config = load_checkpoint()

        if args.mode in ['predict', 'both']:
            # ã‚µãƒ³ãƒ—ãƒ«æ¨è«–
            run_sample_prediction(model, scaler, config)

        if args.mode in ['backtest', 'both']:
            # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
            simple_backtest(model, scaler, config)

        print("\n" + "=" * 60)
        print("âœ… æ¨è«–å®Œäº†!")

    except FileNotFoundError as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        print("\nğŸ’¡ è§£æ±ºæ–¹æ³•:")
        print("   1. ã¾ãš btc_train.py ã‚’å®Ÿè¡Œã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã¦ãã ã•ã„")
        print("   2. å­¦ç¿’å®Œäº†å¾Œã€å†åº¦ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")

    except Exception as e:
        print(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    main()